% ml - bagging, random forest
\newcommand{\bl}[1][m]{b^{[#1]}} % baselearner, default m
\newcommand{\blh}[1][m]{\hat{b}^{[#1]}} % estimated base learner, default m 
\newcommand{\blx}[1][m]{b^{[#1]}(\xv)} % baselearner, default m
\newcommand{\blxi}[1][m]{b^{[#1]}(\xv^{(i)})} % baselearner, default m
\newcommand{\fM}{\hat{f}^{[M]}} % ensembled predictor
\newcommand{\fMx}{\hat{f}^{[M]}(\xv)} % ensembled predictor
\newcommand{\fMh}{\hat{f}^{[M]}(\xv)} % estimated ensembled predictor
\newcommand{\ambifM}{\Delta\left(\fM\right)} % ambiguity/instability of ensemble
\newcommand{\betam}[1][m]{\beta^{[#1]}} % weight of basemodel m
\newcommand{\betamh}[1][m]{\hat{\beta}^{[#1]}} % weight of basemodel m with hat
\newcommand{\betaM}{\beta^{[M]}} % last baselearner
\newcommand{\hbl}[1][m]{b_{h}^{[#1]}} % baselearner hard label, default m
\newcommand{\sbl}[1][m]{b_{\pi}^{[#1]}} % baselearner probs, default m
\newcommand{\hblx}[1][m]{b_{h}^{[#1]}(\xv)} % baselearner hard label, default m
\newcommand{\sblx}[1][m]{b_{\pi}^{[#1]}(\xv)} % baselearner probs, default m
\newcommand{\fMw}{\hat{f}_{\mathbf{w}}^{[M]}} % ensembled predictor weighted
\newcommand{\fMwx}{\hat{f}_{\mathbf{w}}^{[M]}(\xv)} % ensembled predictor weighted
\newcommand{\fMwxi}{\hat{f}_{\mathbf{w}}^{[M]}(\xv^{(i)})} % ensembled predictor weighted
\newcommand{\w}{\mathbf{w}} % ensemble weight vector
\newcommand{\wstar}{\mathbf{w}^{*}} % optimal ensemble weight vector

% ml - boosting
%\newcommand{\fm}[1][m]{f^{[#1]}} % prediction in iteration m
%\newcommand{\fmh}[1][m]{\hat{f}^{[#1]}} % prediction in iteration m
%\newcommand{\fmd}[1][m]{f^{[#1-1]}} % prediction m-1
%\newcommand{\fmdh}[1][m]{\hat{f}^{[#1-1]}} % prediction m-1
%\newcommand{\errm}[1][m]{\text{err}^{[#1]}} % weighted in-sample misclassification rate
%\newcommand{\wm}[1][m]{w^{[#1]}} % weight vector of basemodel m
%\newcommand{\wmi}[1][m]{w^{[#1](i)}} % weight of obs i of basemodel m
%\newcommand{\thetam}[1][m]{\thetab^{[#1]}} % parameters of basemodel m
%\newcommand{\thetamh}[1][m]{\hat{\thetab}^{[#1]}} % parameters of basemodel m with hat
%\newcommand{\blxt}[1][m]{b(\xv, \thetab^{[#1]})} % baselearner, default m
%\newcommand{\ens}{\sum_{m=1}^M \betam \blxt} % ensemble
%\newcommand{\rmm}[1][m]{\tilde{r}^{[#1]}} % pseudo residuals
%\newcommand{\rmi}[1][m]{\tilde{r}^{[#1](i)}} % pseudo residuals
%\newcommand{\Rtm}[1][m]{R_{t}^{[#1]}} % terminal-region
%\newcommand{\Tm}[1][m]{T^{[#1]}} % terminal-region
%\newcommand{\ctm}[1][m]{c_t^{[#1]}} % mean, terminal-regions
%\newcommand{\ctmh}[1][m]{\hat{c}_t^{[#1]}} % mean, terminal-regions with hat
%\newcommand{\ctmt}[1][m]{\tilde{c}_t^{[#1]}} % mean, terminal-regions
%\newcommand{\Lp}{L^\prime}
%\newcommand{\Ldp}{L^{\prime\prime}}
%\newcommand{\Lpleft}{\Lp_{\text{left}}}

% ml - boosting iml lecture
%\newcommand{\ts}{\thetab^{\star}} % theta*
%\newcommand{\bljt}{\bl[j](\xv, \thetab)} % BL j with theta
%\newcommand{\bljts}{\bl[j](\xv, \ts)} % BL j with theta*