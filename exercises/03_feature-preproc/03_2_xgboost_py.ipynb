{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning: In-class Exercise 03-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Our goal for this exercise sheet is to understand how to apply and work with XGBoost. The XGBoost algorithm has a large range of hyperparameters. We learn specifically how to tune these hyperparameters to optimize our XGBoost model for the task at hand.\n",
    "\n",
    "## German Credit Dataset\n",
    "\n",
    "As in previous exercises, we use the German credit dataset of Prof. Dr. Hans Hoffman of the University of Hamburg in 1994. By using XGBoost, we want to classify people as a good or bad credit risk based on 20 personal, demographic and financial features. The dataset is available at the UCI repository as Statlog (German Credit Data) Data Set.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "To apply the XGBoost algorithm to the credit dataset, categorical features need to be converted into numeric features, e.g. using one-hot encoding. In the Python solution, we load the dataset using `fetch_openml` from scikit-learn. We then separate the features (`X`) and the target (`y`), and encode the target variable using `LabelEncoder` by mapping 'bad' to 0 and 'good' to 1. Next, we identify the categorical columns by selecting those with the object or category data type and set up a `ColumnTransformer` that applies `OneHotEncoder` to these columns while passing through the numerical features unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Load the German credit dataset from OpenML\n",
    "X, y = fetch_openml(\"credit-g\", version=1, as_frame=True, return_X_y=True)\n",
    "\n",
    "# Encode the target variable: 'good' as 1 and 'bad' as 0\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(['bad', 'good'])  # Explicitly define the mapping\n",
    "y = label_encoder.transform(y)\n",
    "\n",
    "# Identify categorical columns (assumes object or category dtype)\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Set up a ColumnTransformer to one-hot encode categorical features while passing through numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 XGBoost Learner\n",
    "\n",
    "### 1.1 Initialize an XGBoost Learner\n",
    "\n",
    "Initialize an XGBoost classifier from scikit-learn with 100 boosting rounds. Make sure that you have installed the Python package `xgboost`.\n",
    "\n",
    "In XGBoost for Python (scikit-learn API), the number of iterations (also known as boosting rounds or trees) is specified via the parameter `n_estimators`. This hyperparameter determines the total number of boosting iterations performed by the model.\n",
    "\n",
    "There is a trade-off between underfitting (not enough iterations) and overfitting (too many iterations). Therefore, it is always better to tune such a hyperparameter. In this exercise, we choose 100 iterations as we believe it provides a good upper bound. Later, we will introduce early stopping to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=100, \n",
    "                        random_state=42, \n",
    "                        eval_metric='logloss')\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Performance Assessment using Cross-validation\n",
    "\n",
    "Use 5-fold cross-validation to estimate the generalization error of the XGBoost classifier with 100 boosting iterations on the one-hot-encoded German credit dataset. Measure the learner's performance using classification accuracy. \n",
    "\n",
    "Specifically, you need to conduct three steps:\n",
    "\n",
    "1. Use `cross_val_score()` from scikit-learn with the pipeline defined above.\n",
    "2. Set the parameter `cv=5` to specify 5-fold cross-validation.\n",
    "3. Aggregate the performance scores by computing the mean accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.735 0.76  0.735 0.74  0.765]\n",
      "Mean CV accuracy: 0.7470\n"
     ]
    }
   ],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hyperparameters\n",
    "\n",
    "### 2.1 Overview of Hyperparameters\n",
    "\n",
    "Apart from the number of iterations (`n_estimators`), the XGBoost classifier has several other hyperparameters which were kept to their default values in the previous exercise. Extract an overview of all hyperparameters from the initialized XGBoost classifier (previous exercise) and their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost hyperparameters with the configured values:\n",
      "objective: binary:logistic\n",
      "base_score: None\n",
      "booster: None\n",
      "callbacks: None\n",
      "colsample_bylevel: None\n",
      "colsample_bynode: None\n",
      "colsample_bytree: None\n",
      "device: None\n",
      "early_stopping_rounds: None\n",
      "enable_categorical: False\n",
      "eval_metric: logloss\n",
      "feature_types: None\n",
      "feature_weights: None\n",
      "gamma: None\n",
      "grow_policy: None\n",
      "importance_type: None\n",
      "interaction_constraints: None\n",
      "learning_rate: None\n",
      "max_bin: None\n",
      "max_cat_threshold: None\n",
      "max_cat_to_onehot: None\n",
      "max_delta_step: None\n",
      "max_depth: None\n",
      "max_leaves: None\n",
      "min_child_weight: None\n",
      "missing: nan\n",
      "monotone_constraints: None\n",
      "multi_strategy: None\n",
      "n_estimators: 100\n",
      "n_jobs: None\n",
      "num_parallel_tree: None\n",
      "random_state: 42\n",
      "reg_alpha: None\n",
      "reg_lambda: None\n",
      "sampling_method: None\n",
      "scale_pos_weight: None\n",
      "subsample: None\n",
      "tree_method: None\n",
      "validate_parameters: None\n",
      "verbosity: None\n"
     ]
    }
   ],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "params = xgb_clf.get_params()\n",
    "\n",
    "print(\"XGBoost hyperparameters with the configured values:\")\n",
    "for param, value in params.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and Answers\n",
    "1. Does the learner rely on a tree or a linear booster by default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "===SOLUTION===\n",
    "\n",
    "The default booster in XGBoost is \"gbtree\", meaning it uses a tree-based booster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do more hyperparameters exist for the tree or the linear booster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "===SOLUTION===\n",
    "\n",
    "The tree booster (gbtree) has a richer set of hyperparameters (such as max_depth, min_child_weight, subsample, colsample_bytree, etc.) compared to the linear booster, which typically has fewer hyperparameters (like lambda, alpha, and lambda_bias for regularization).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. What do `max_depth`, `eta`, `n_estimators` mean and what are their default values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "===SOLUTION===\n",
    "\n",
    "`max_depth`: Controls the maximum depth of the trees. Its default value is 6.\n",
    "`eta`: Represents the learning rate, which determines the contribution of each tree to the overall model. The default value is 0.3. In Python’s XGBoost, the number of boosting rounds is managed by the parameter `n_estimators` (analogous to nrounds in R), which we have set to 100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Does a larger value for `eta` imply a larger value for `n_estimators`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "===SOLUTION===\n",
    "\n",
    "No, a larger `eta` means that each tree has a larger impact on the overall model. Consequently, if `eta` is increased, fewer boosting rounds (lower `n_estimators`) are typically needed to avoid overfitting, not more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tune Hyperparameters\n",
    "\n",
    "Tune the tree depth (`max_depth`) and the learning rate (`learning_rate`, alias for `eta`) of the XGBoost classifier on the German credit dataset using random search:\n",
    "\n",
    "- Search space:\n",
    "    - `max_depth`: integer values between 1 and 8.\n",
    "    - `learning_rate`: continuous values between 0.2 and 0.4. Note: in practice the learning rate is usually much smaller. The range of large learning rates here is only for an educational purpose, so that you can train the models faster on your laptop.\n",
    "- Termination criterion: Perform 20 evaluations.\n",
    "- Performance measure: Classification error (equivalent to 1 - accuracy). Note: This dataset is imbalanced, so accuracy is not an ideal evaluation metric. For now, we'll use (1 - accuracy), but you'll later learn how to apply more advanced metrics that are better suited for imbalanced classification tasks.\n",
    "- Resampling strategy: 3-fold cross-validation.\n",
    "\n",
    "<details><summary>Hint 1:</summary>\n",
    "Use `scipy.stats.uniform` to instantiate a uniform distribution, and use it for the search space of `learning_rate`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                                                remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;cat&#x27;,\n",
       "                                                                               OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                                               [&#x27;checking_status&#x27;,\n",
       "                                                                                &#x27;credit_history&#x27;,\n",
       "                                                                                &#x27;purpose&#x27;,\n",
       "                                                                                &#x27;savings_status&#x27;,\n",
       "                                                                                &#x27;employment&#x27;,\n",
       "                                                                                &#x27;personal_status&#x27;,\n",
       "                                                                                &#x27;other_parties&#x27;,\n",
       "                                                                                &#x27;property_magnitude&#x27;,\n",
       "                                                                                &#x27;other_payment_plans...\n",
       "                                                            n_estimators=100,\n",
       "                                                            n_jobs=None,\n",
       "                                                            num_parallel_tree=None, ...))]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x10690b670&gt;,\n",
       "                                        &#x27;classifier__max_depth&#x27;: [1, 2, 3, 4, 5,\n",
       "                                                                  6, 7, 8]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(classification_error, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                                                remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;cat&#x27;,\n",
       "                                                                               OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                                               [&#x27;checking_status&#x27;,\n",
       "                                                                                &#x27;credit_history&#x27;,\n",
       "                                                                                &#x27;purpose&#x27;,\n",
       "                                                                                &#x27;savings_status&#x27;,\n",
       "                                                                                &#x27;employment&#x27;,\n",
       "                                                                                &#x27;personal_status&#x27;,\n",
       "                                                                                &#x27;other_parties&#x27;,\n",
       "                                                                                &#x27;property_magnitude&#x27;,\n",
       "                                                                                &#x27;other_payment_plans...\n",
       "                                                            n_estimators=100,\n",
       "                                                            n_jobs=None,\n",
       "                                                            num_parallel_tree=None, ...))]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classifier__learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x10690b670&gt;,\n",
       "                                        &#x27;classifier__max_depth&#x27;: [1, 2, 3, 4, 5,\n",
       "                                                                  6, 7, 8]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(classification_error, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;checking_status&#x27;,\n",
       "                                                   &#x27;credit_history&#x27;, &#x27;purpose&#x27;,\n",
       "                                                   &#x27;savings_status&#x27;,\n",
       "                                                   &#x27;employment&#x27;,\n",
       "                                                   &#x27;personal_status&#x27;,\n",
       "                                                   &#x27;other_parties&#x27;,\n",
       "                                                   &#x27;property_magnitude&#x27;,\n",
       "                                                   &#x27;other_payment_plans&#x27;,\n",
       "                                                   &#x27;housing&#x27;, &#x27;job&#x27;,\n",
       "                                                   &#x27;own_telephone&#x27;,...\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.32367720186661747, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=4,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(force_int_remainder_cols=False, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;checking_status&#x27;, &#x27;credit_history&#x27;,\n",
       "                                  &#x27;purpose&#x27;, &#x27;savings_status&#x27;, &#x27;employment&#x27;,\n",
       "                                  &#x27;personal_status&#x27;, &#x27;other_parties&#x27;,\n",
       "                                  &#x27;property_magnitude&#x27;, &#x27;other_payment_plans&#x27;,\n",
       "                                  &#x27;housing&#x27;, &#x27;job&#x27;, &#x27;own_telephone&#x27;,\n",
       "                                  &#x27;foreign_worker&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;checking_status&#x27;, &#x27;credit_history&#x27;, &#x27;purpose&#x27;, &#x27;savings_status&#x27;, &#x27;employment&#x27;, &#x27;personal_status&#x27;, &#x27;other_parties&#x27;, &#x27;property_magnitude&#x27;, &#x27;other_payment_plans&#x27;, &#x27;housing&#x27;, &#x27;job&#x27;, &#x27;own_telephone&#x27;, &#x27;foreign_worker&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;duration&#x27;, &#x27;credit_amount&#x27;, &#x27;installment_commitment&#x27;, &#x27;residence_since&#x27;, &#x27;age&#x27;, &#x27;existing_credits&#x27;, &#x27;num_dependents&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.32367720186661747,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                                                remainder='passthrough',\n",
       "                                                                transformers=[('cat',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                               ['checking_status',\n",
       "                                                                                'credit_history',\n",
       "                                                                                'purpose',\n",
       "                                                                                'savings_status',\n",
       "                                                                                'employment',\n",
       "                                                                                'personal_status',\n",
       "                                                                                'other_parties',\n",
       "                                                                                'property_magnitude',\n",
       "                                                                                'other_payment_plans...\n",
       "                                                            n_estimators=100,\n",
       "                                                            n_jobs=None,\n",
       "                                                            num_parallel_tree=None, ...))]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'classifier__learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x10690b670>,\n",
       "                                        'classifier__max_depth': [1, 2, 3, 4, 5,\n",
       "                                                                  6, 7, 8]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(classification_error, greater_is_better=False, response_method='predict'),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Define a custom scoring function: classification error = 1 - accuracy.\n",
    "# Setting greater_is_better=False so that lower error is better.\n",
    "def classification_error(y_true, y_pred):\n",
    "    return 1 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "error_scorer = make_scorer(classification_error, greater_is_better=False)\n",
    "\n",
    "# Define the search space.\n",
    "# Note: Since our pipeline names the XGBoost classifier step \"classifier\",\n",
    "# we specify the hyperparameters with the prefix \"classifier__\".\n",
    "param_distributions = {\n",
    "    \"classifier__max_depth\": list(range(1, 9)),\n",
    "    \"classifier__learning_rate\": uniform(0.2, 0.2) \n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV with 20 random evaluations and 3-fold cross-validation.\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    scoring=error_scorer,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Execute the hyperparameter tuning on the training data.\n",
    "random_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Inspect the Best Performing Setup\n",
    "Which tree depth was the best performing one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'classifier__learning_rate': 0.32367720186661747, 'classifier__max_depth': 4}\n",
      "Best classification error: 0.2350\n"
     ]
    }
   ],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "# Display the best hyperparameters and corresponding classification error.\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "# Note: The best_score_ is negative classification error (because greater_is_better=False)\n",
    "print(f\"Best classification error: {-random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Early Stopping\n",
    "\n",
    "### 3.1 Set up an XGBoost Learner with Early Stopping\n",
    "\n",
    "Now that we've derived the best hyperparameters for `max_depth` and `learning_rate`, we can train our final model. To avoid overfitting, we perform early stopping. Early stopping halts training when the performance on a validation dataset stops improving for a specified number of iterations.\n",
    "\n",
    "Set up an XGBoost classifier with the following hyperparameters:\n",
    "\n",
    "- `max_depth` and `learning_rate` set according to the best values identified from the tuning step.\n",
    "- `n_estimators` set to 100.\n",
    "- Early stopping set to 5 rounds (this parameter could also be tuned, but we simplify the exercise here).\n",
    "\n",
    "Split the `X` and `y` into a training set and a tes set, with `test_size=0.1`.\n",
    "\n",
    "<details><summary>Hint 1:</summary>\n",
    "Since our original pipeline contains a preprocessor, we need to ensure that both the training and validation sets are preprocessed in the same way. Here we fit the preprocessor on the training subset and transform both sets.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "best_max_depth = random_search.best_params_['classifier__max_depth']\n",
    "best_learning_rate = random_search.best_params_['classifier__learning_rate']\n",
    "\n",
    "# Partition the training set (X_train, y_train) into training (90%) and early stopping (validation) sets (10%)\n",
    "X_train_es, X_val_es, y_train_es, y_val_es = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize a new XGBoost classifier with early stopping.\n",
    "# Note: n_estimators corresponds to nrounds in R.\n",
    "xgb_es = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=best_max_depth,\n",
    "    learning_rate=best_learning_rate,\n",
    "    early_stopping_rounds=5,\n",
    "    random_state=2001,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Since our original pipeline contains a preprocessor, we need to ensure that both\n",
    "# the training and validation sets are preprocessed in the same way.\n",
    "# Here we fit the preprocessor on the training subset and transform both sets.\n",
    "preprocessor.fit(X_train_es)\n",
    "X_train_es_trans = preprocessor.transform(X_train_es)\n",
    "X_val_es_trans = preprocessor.transform(X_val_es)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training on Credit Data\n",
    "\n",
    "Train the XGBoost classifier with early stopping from the training set obtained in the last chunk of exercise. How many iterations were conducted before the boosting algorithm stopped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.55338\n",
      "[1]\tvalidation_0-logloss:0.51626\n",
      "[2]\tvalidation_0-logloss:0.50632\n",
      "[3]\tvalidation_0-logloss:0.48498\n",
      "[4]\tvalidation_0-logloss:0.46744\n",
      "[5]\tvalidation_0-logloss:0.47045\n",
      "[6]\tvalidation_0-logloss:0.46659\n",
      "[7]\tvalidation_0-logloss:0.46170\n",
      "[8]\tvalidation_0-logloss:0.44685\n",
      "[9]\tvalidation_0-logloss:0.44670\n",
      "[10]\tvalidation_0-logloss:0.45028\n",
      "[11]\tvalidation_0-logloss:0.44845\n",
      "[12]\tvalidation_0-logloss:0.44415\n",
      "[13]\tvalidation_0-logloss:0.44018\n",
      "[14]\tvalidation_0-logloss:0.43668\n",
      "[15]\tvalidation_0-logloss:0.43682\n",
      "[16]\tvalidation_0-logloss:0.43732\n",
      "[17]\tvalidation_0-logloss:0.43450\n",
      "[18]\tvalidation_0-logloss:0.43009\n",
      "[19]\tvalidation_0-logloss:0.43432\n",
      "[20]\tvalidation_0-logloss:0.43173\n",
      "[21]\tvalidation_0-logloss:0.43376\n",
      "[22]\tvalidation_0-logloss:0.42858\n",
      "[23]\tvalidation_0-logloss:0.42894\n",
      "[24]\tvalidation_0-logloss:0.43310\n",
      "[25]\tvalidation_0-logloss:0.43090\n",
      "[26]\tvalidation_0-logloss:0.42902\n",
      "[27]\tvalidation_0-logloss:0.43151\n",
      "Classification error with early stopping: 0.21\n",
      "Number of trees used with early stopping: 22\n"
     ]
    }
   ],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "xgb_es.fit(\n",
    "    X_train_es_trans,\n",
    "    y_train_es,\n",
    "    eval_set=[(X_val_es_trans, y_val_es)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluate the performance on the validation set.\n",
    "y_val_pred = xgb_es.predict(X_val_es_trans)\n",
    "val_accuracy = accuracy_score(y_val_es, y_val_pred)\n",
    "print(f\"Classification error with early stopping: {(1 - val_accuracy):.2f}\")\n",
    "\n",
    "# Store the number of iterations (trees) used by the model with early stopping\n",
    "best_iteration = xgb_es.best_iteration\n",
    "print(f\"Number of trees used with early stopping: {best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Extra: Nested Resampling\n",
    "\n",
    "To obtain an unbiased performance estimate while tuning hyperparameters and applying early stopping, conduct nested resampling with:\n",
    "\n",
    "- **3-fold cross-validation** for both the outer and inner resampling loops.\n",
    "- **Search space**:\n",
    "    - `max_depth` between 1 and 8.\n",
    "    - `learning_rate` (eta) between 0.2 and 0.4.\n",
    "- **Random search** with 20 evaluations.\n",
    "- **Performance measure**: classification error (`1 - accuracy`).\n",
    "\n",
    "Extract the performance estimate on the outer resampling folds.\n",
    "\n",
    "<details><summary>Hint 1:</summary>\n",
    "    Note: Because early stopping in XGBoost requires a separate validation set, \n",
    "    we wrap XGBClassifier in a custom estimator that automatically partitions the training data for early stopping. This estimator should inherit `sklearn.base.BaseEstimator` and `ClassifierMixin` and implement the required interfaces. Furthermore, in `def fit(self, X, y)`, the this class should partition the `X` and `y` (training data) into a \"local\" training and a \"local\" validation subsets. These \"local\" training and validation sets are further passed into `XGBClassifier.fit(X_train_local, y_train_local, eval_set=[(X_val_local, y_val_local)])` to perform the training with early stopping.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Nested CV Classification Error: 0.2580\n"
     ]
    }
   ],
   "source": [
    "#===SOLUTION===\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "# Custom wrapper to enable early stopping within a pipeline.\n",
    "class XGBClassifierWithEarlyStopping(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Note: Because early stopping in XGBoost requires a separate validation set, \n",
    "    we wrap XGBClassifier in a custom estimator that automatically partitions the training data for early stopping.\n",
    "\n",
    "    However, the drawback is that the training data is split into two parts, \n",
    "    which means that the model is trained on less data. If you have better solutions to utilizing the inner CV validation set\n",
    "    for the early stopping validation set, please submit a PR.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators: int =100, max_depth: int = 6, learning_rate: float = 0.3,\n",
    "                 early_stopping_rounds: int = 5, test_size: float = 0.1, random_state: int = None, **kwargs):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.kwargs = kwargs\n",
    "        self.model_: XGBClassifier = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Partition data for early stopping: inner training and validation splits.\n",
    "        X_train_local, X_val_local, y_train_local, y_val_local = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        self.model_ = XGBClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            learning_rate=self.learning_rate,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            random_state=self.random_state,\n",
    "            eval_metric='logloss',\n",
    "            **self.kwargs\n",
    "        )\n",
    "        self.model_.fit(\n",
    "            X_train_local, y_train_local,\n",
    "            eval_set=[(X_val_local, y_val_local)],\n",
    "            verbose=False\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict_proba(X)\n",
    "\n",
    "# Build a pipeline that applies preprocessing then the custom XGBoost classifier.\n",
    "# We assume the preprocessor (e.g., a ColumnTransformer for one-hot encoding) is defined earlier.\n",
    "pipeline_es = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifierWithEarlyStopping(\n",
    "        n_estimators=100,\n",
    "        max_depth=6, \n",
    "        learning_rate=0.3,   \n",
    "        early_stopping_rounds=best_iteration,\n",
    "        test_size=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Define the custom scoring: classification error = 1 - accuracy.\n",
    "def classification_error(y_true, y_pred):\n",
    "    return 1 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "error_scorer = make_scorer(classification_error, greater_is_better=False)\n",
    "\n",
    "# Define the search space for hyperparameter tuning.\n",
    "param_distributions_nested = {\n",
    "    \"classifier__max_depth\": list(range(1, 9)),\n",
    "    \"classifier__learning_rate\": uniform(0.2, 0.2)      \n",
    "}\n",
    "\n",
    "# Inner resampling: 3-fold CV using RandomizedSearchCV with 20 evaluations.\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "random_search_nested = RandomizedSearchCV(\n",
    "    pipeline_es,\n",
    "    param_distributions=param_distributions_nested,\n",
    "    n_iter=20,   \n",
    "    scoring=error_scorer,\n",
    "    cv=inner_cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Outer resampling: perform 3-fold CV over the entire dataset (X, y).\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "nested_scores = cross_val_score(\n",
    "    random_search_nested,\n",
    "    X,\n",
    "    y,\n",
    "    cv=outer_cv,\n",
    "    scoring=error_scorer,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Since error_scorer was defined with greater_is_better=False, scores are negative.\n",
    "mean_classification_error = -np.mean(nested_scores)\n",
    "print(f\"Nested CV Classification Error: {mean_classification_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How is the classification error compared to the previous experiment without nested sampling? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "===SOLUTION===\n",
    "\n",
    "We obtain a higher classification error than we received without nested resampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this exercise sheet, we learned how to apply a XGBoost learner to the credit data set By using resampling, we estimated the performance. XGBoost has a lot of hyperparameters and we only had a closer look on two of them. We also saw how early stopping could be facilitated which should help to avoid overfitting of the XGBoost model.\n",
    "\n",
    "Interestingly, we obtained best results, when we used 100 iterations, without tuning or early stopping. However, performance differences were quite small - if we set a different seed, we might see a different ranking. Furthermore, we could extend our tuning search space such that more hyperparameters are considered to increase overall performance of the learner for the task at hand. Of course, this also requires more budget for the tuning (e.g., more evaluations of random search)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
